{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d121a9",
   "metadata": {},
   "source": [
    "## Part3: The Problem of Fairness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_data] ZIP intersection: 1375 common of (pop=1646, cls=1534)\n",
      "[load_data] Dropped infeasible ZIPs: ['11219']\n",
      "[load_data] areas: 1374, facilities (before filter): 15014, (after filter): 15013, sites: 215400\n",
      "[conflict_pairs] conflict pairs found: 81383\n",
      "[main] Building fairness model (Section 6)...\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter MIPGap to value 0.005\n",
      "[main] Optimizing fairness model...\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (mac64[arm] - Darwin 25.0.0 25A362)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "MIPGap  0.005\n",
      "\n",
      "Optimize a model with 1723833 rows, 1416628 columns and 7578827 nonzeros\n",
      "Model fingerprint: 0x7821483a\n",
      "Variable types: 770428 continuous, 646200 integer (646200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 1e+05]\n",
      "  Objective range  [3e-01, 7e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e-01, 1e+08]\n",
      "Presolve removed 235121 rows and 234873 columns\n",
      "Presolve time: 0.40s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 1.34 seconds (1.66 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 0\n",
      "No other solutions better than -1e+100\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n",
      "[main] Model not solved to optimality. Status: 3 SolCount: 0\n",
      "[main] Model infeasible -> computing IIS...\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (mac64[arm] - Darwin 25.0.0 25A362)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "MIPGap  0.005\n",
      "\n",
      "\n",
      "IIS computed: 1 constraints, 7 bounds\n",
      "IIS runtime: 0.04 seconds (0.00 work units)\n",
      "[main] IIS constraints: ['cov_identity_tot_10014']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "POP_FILE   = Path(\"Project 1 Data- version 0.0- Yue Chen/population_calculated.csv\")\n",
    "CLASS_FILE = Path(\"Project 1 Data- version 0.0- Yue Chen/demand_classification.csv\")\n",
    "FAC_FILE   = Path(\"Project 1 Data- version 0.0- Yue Chen/child_care_regulated_cleaned.csv\")\n",
    "SITE_FILE  = Path(\"Project 1 Data- version 0.0- Yue Chen/potential_locations.csv\")\n",
    "\n",
    "\n",
    "BUDGET_B = 100_000_000        \n",
    "W0_5 = 2.0 / 3.0\n",
    "W5_12 = 1.0 / 3.0\n",
    "BETA = 100.0                  \n",
    "DELTA = 0.06                  \n",
    "Q05_IMPUTE_RATIO = 1\n",
    "\n",
    "DEFAULT_SIZES = pd.DataFrame({\n",
    "    \"k\": [\"S\", \"M\", \"L\"],\n",
    "    \"cap_k\": [100, 200, 400],\n",
    "    \"cap_k_0_5\": [50, 100, 200],\n",
    "    \"cost_k\": [65000, 95000, 115000],\n",
    "})\n",
    "\n",
    "# ------------------------------\n",
    "# Helper functions (copied/compatible with your Part2)\n",
    "# ------------------------------\n",
    "def pad_zip(z):\n",
    "    if pd.isna(z):\n",
    "        return \"\"\n",
    "    s = str(z).strip()\n",
    "    if s.endswith(\".0\"):\n",
    "        s = s[:-2]\n",
    "    return s.zfill(5)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    if any(pd.isna(v) for v in (lat1, lon1, lat2, lon2)):\n",
    "        return np.inf\n",
    "    R = 3958.8\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    a = np.sin((lat2 - lat1) / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2.0)**2\n",
    "    return 2.0 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def cost_segments(n):\n",
    "    if n <= 0 or pd.isna(n):\n",
    "        large = 1e6\n",
    "        return (large, large, large)\n",
    "    return ((20000 + 200.0 * n) / n,\n",
    "            (20000 + 400.0 * n) / n,\n",
    "            (20000 + 1000.0 * n) / n)\n",
    "\n",
    "# ------------------------------\n",
    "# Data loading (kept compatible with your part2 load_data)\n",
    "# ------------------------------\n",
    "def load_data():\n",
    "    pop = pd.read_csv(POP_FILE)\n",
    "    pop[\"zip_code_cleaned\"] = pop[\"zip_code_cleaned\"].apply(pad_zip)\n",
    "    pop.rename(columns={\"Population_0_12\": \"pop_0_12\", \"Population_0_5\": \"pop_0_5\"}, inplace=True)\n",
    "    pop[\"pop_0_12\"] = pd.to_numeric(pop.get(\"pop_0_12\", 0), errors=\"coerce\").fillna(0)\n",
    "    pop[\"pop_0_5\"]  = pd.to_numeric(pop.get(\"pop_0_5\", 0), errors=\"coerce\").fillna(0)\n",
    "\n",
    "    cls = pd.read_csv(CLASS_FILE)\n",
    "    cls[\"zip_code_cleaned\"] = cls[\"zip_code_cleaned\"].apply(pad_zip)\n",
    "    cls.rename(columns={\"Demand_Classification\": \"class\"}, inplace=True)\n",
    "    cls[\"class\"] = cls[\"class\"].astype(str).str.strip().str.lower()\n",
    "    cls[\"t_i\"] = np.where(cls[\"class\"].str.contains(\"high\", na=False), 0.5, 1/3)\n",
    "\n",
    "    common_zips = set(pop[\"zip_code_cleaned\"]) & set(cls[\"zip_code_cleaned\"])\n",
    "    print(f\"[load_data] ZIP intersection: {len(common_zips)} common of (pop={len(pop)}, cls={len(cls)})\")\n",
    "\n",
    "    pop = pop[pop[\"zip_code_cleaned\"].isin(common_zips)].copy()\n",
    "    cls = cls[cls[\"zip_code_cleaned\"].isin(common_zips)].copy()\n",
    "    \n",
    "    areas = pop.merge(cls[[\"zip_code_cleaned\", \"t_i\"]], on=\"zip_code_cleaned\", how=\"inner\")\n",
    "    areas[\"pop_0_12\"] = areas[\"pop_0_12\"].fillna(0)\n",
    "    areas[\"pop_0_5\"] = areas[\"pop_0_5\"].fillna(0)\n",
    "    areas[\"t_i\"] = areas[\"t_i\"].fillna(1/3)\n",
    "\n",
    "    fac = pd.read_csv(FAC_FILE)\n",
    "    fac[\"zip_code_cleaned\"] = fac[\"zip_code_cleaned\"].apply(pad_zip)\n",
    "    if \"total_capacity\" in fac.columns:\n",
    "        fac.rename(columns={\"total_capacity\": \"n_f\"}, inplace=True)\n",
    "    if \"latitude\" in fac.columns:\n",
    "        fac.rename(columns={\"latitude\": \"lat\"}, inplace=True)\n",
    "    if \"longitude\" in fac.columns:\n",
    "        fac.rename(columns={\"longitude\": \"lon\"}, inplace=True)\n",
    "\n",
    "    if \"q_0_5\" not in fac.columns:\n",
    "        if all(col in fac.columns for col in [\"infant_capacity\", \"toddler_capacity\", \"preschool_capacity\"]):\n",
    "            fac[\"q_0_5\"] = fac[\"infant_capacity\"].fillna(0) + fac[\"toddler_capacity\"].fillna(0) + fac[\"preschool_capacity\"].fillna(0)\n",
    "        else:\n",
    "            fac[\"n_f\"] = pd.to_numeric(fac.get(\"n_f\", 0), errors=\"coerce\").fillna(0)\n",
    "            fac[\"q_0_5\"] = (fac[\"n_f\"] * Q05_IMPUTE_RATIO).round(0)\n",
    "\n",
    "    fac = fac[[\"facility_id\", \"zip_code_cleaned\", \"n_f\", \"q_0_5\", \"lat\", \"lon\"]].copy()\n",
    "    fac[\"n_f\"] = pd.to_numeric(fac[\"n_f\"], errors=\"coerce\").fillna(0)\n",
    "    fac[\"q_0_5\"] = pd.to_numeric(fac[\"q_0_5\"], errors=\"coerce\").fillna(0)\n",
    "    before_fac_count = len(fac)\n",
    "    fac = fac[fac[\"n_f\"] > 0].copy()\n",
    "    after_fac_count = len(fac)\n",
    "\n",
    "    site = pd.read_csv(SITE_FILE)\n",
    "    site.rename(columns={\"zipcode\": \"zip_code_cleaned\", \"latitude\": \"lat\", \"longitude\": \"lon\"}, inplace=True)\n",
    "    site[\"zip_code_cleaned\"] = site[\"zip_code_cleaned\"].apply(pad_zip)\n",
    "    site[\"site_id\"] = np.arange(1, len(site) + 1)\n",
    "    site = site[[\"site_id\", \"zip_code_cleaned\", \"lat\", \"lon\"]].copy()\n",
    "\n",
    "    sizes = DEFAULT_SIZES.copy()\n",
    "\n",
    "    drop_zips = [\"11219\"]\n",
    "    areas = areas[~areas[\"zip_code_cleaned\"].isin(drop_zips)].copy()\n",
    "    print(f\"[load_data] Dropped infeasible ZIPs: {drop_zips}\")\n",
    "    print(f\"[load_data] areas: {len(areas)}, facilities (before filter): {before_fac_count}, (after filter): {after_fac_count}, sites: {len(site)}\")\n",
    "    return areas, fac, site, sizes\n",
    "\n",
    "# ------------------------------\n",
    "# Spatial helpers (compatible)\n",
    "# ------------------------------\n",
    "def infer_sites(sites, facs, delta=DELTA):\n",
    "    sites = sites.copy()\n",
    "    sites[\"allowed\"] = 1\n",
    "    if len(facs) == 0:\n",
    "        sites[\"allowed\"] = 1\n",
    "        return sites\n",
    "    for i, s in sites.iterrows():\n",
    "        zf = facs[facs[\"zip_code_cleaned\"] == s[\"zip_code_cleaned\"]]\n",
    "        infeasible = False\n",
    "        for _, f in zf.iterrows():\n",
    "            if haversine(s[\"lat\"], s[\"lon\"], f[\"lat\"], f[\"lon\"]) < delta:\n",
    "                infeasible = True\n",
    "                break\n",
    "        sites.loc[i, \"allowed\"] = 0 if infeasible else 1\n",
    "    return sites\n",
    "\n",
    "def conflict_pairs(sites, delta=DELTA):\n",
    "    pairs = []\n",
    "    if len(sites) == 0:\n",
    "        return pairs\n",
    "    for zip_i, grp in sites.groupby(\"zip_code_cleaned\"):\n",
    "        idxs = list(grp.index)\n",
    "        if len(idxs) < 2:\n",
    "            continue\n",
    "        for i, j in combinations(idxs, 2):\n",
    "            if haversine(grp.loc[i, \"lat\"], grp.loc[i, \"lon\"], grp.loc[j, \"lat\"], grp.loc[j, \"lon\"]) < delta:\n",
    "                pairs.append((grp.loc[i, \"site_id\"], grp.loc[j, \"site_id\"]))\n",
    "    print(f\"[conflict_pairs] conflict pairs found: {len(pairs)}\")\n",
    "    return pairs\n",
    "\n",
    "# ------------------------------\n",
    "# Build fairness model \n",
    "# ------------------------------\n",
    "def build_fairness_model(areas, facs, sites, sizes, pairs, time_limit=300, mip_gap=0.01, B=BUDGET_B):\n",
    "    \n",
    "    I = list(areas[\"zip_code_cleaned\"])\n",
    "    F = list(facs[\"facility_id\"])\n",
    "    S = list(sites[\"site_id\"])\n",
    "    K = list(sizes[\"k\"])\n",
    "\n",
    "\n",
    "    nf   = dict(zip(facs.facility_id, facs.n_f))\n",
    "    q05  = dict(zip(facs.facility_id, facs.q_0_5))\n",
    "    zip_f = dict(zip(facs.facility_id, facs.zip_code_cleaned))\n",
    "    zip_s = dict(zip(sites.site_id, sites.zip_code_cleaned))\n",
    "    ti   = dict(zip(areas.zip_code_cleaned, areas.t_i))\n",
    "    Pi   = dict(zip(areas.zip_code_cleaned, areas.pop_0_12))\n",
    "    Pi05 = dict(zip(areas.zip_code_cleaned, areas.pop_0_5))\n",
    "    cap  = dict(zip(sizes.k, sizes.cap_k))\n",
    "    cap05= dict(zip(sizes.k, sizes.cap_k_0_5))\n",
    "    cost = dict(zip(sizes.k, sizes.cost_k))\n",
    "    allow= dict(zip(sites.site_id, sites.allowed if \"allowed\" in sites.columns else [1]*len(sites)))\n",
    "\n",
    "    cap = {k: float(v) for k, v in cap.items()}\n",
    "    cap05 = {k: float(v) for k, v in cap05.items()}\n",
    "    cost = {k: float(v) for k, v in cost.items()}\n",
    "\n",
    "    c1 = {f: cost_segments(nf.get(f, 0))[0] for f in F}\n",
    "    c2 = {f: cost_segments(nf.get(f, 0))[1] for f in F}\n",
    "    c3 = {f: cost_segments(nf.get(f, 0))[2] for f in F}\n",
    "\n",
    "    m = gp.Model(\"Part3_Fairness\")\n",
    "    m.Params.OutputFlag = 1\n",
    "    m.setParam(\"TimeLimit\", time_limit)\n",
    "    m.setParam(\"MIPGap\", mip_gap)\n",
    "\n",
    "    x1 = m.addVars(F, lb=0.0, name=\"x1\") if F else {}\n",
    "    x2 = m.addVars(F, lb=0.0, name=\"x2\") if F else {}\n",
    "    x3 = m.addVars(F, lb=0.0, name=\"x3\") if F else {}\n",
    "    y1 = m.addVars(F, lb=0.0, ub=1.0, name=\"y1\") if F else {}\n",
    "    y2 = m.addVars(F, lb=0.0, ub=1.0, name=\"y2\") if F else {}\n",
    "    y3 = m.addVars(F, lb=0.0, ub=1.0, name=\"y3\") if F else {}\n",
    "    xF = m.addVars(F, lb=0.0, name=\"xF\") if F else {}\n",
    "    z05 = m.addVars(F, lb=0.0, name=\"z05\") if F else {}\n",
    "\n",
    "    y_sk = m.addVars(S, K, vtype=GRB.BINARY, name=\"y_sk\") if S and K else {}\n",
    "    u_sk05 = m.addVars(S, K, lb=0.0, name=\"u_sk05\") if S and K else {}\n",
    "\n",
    "    r05 = m.addVars(I, lb=0.0, ub=1.0, name=\"r05\") if I else {}\n",
    "    r512 = m.addVars(I, lb=0.0, ub=1.0, name=\"r512\") if I else {}\n",
    "    g = m.addVars(I, lb=0.0, ub=1.0, name=\"g\") if I else {}\n",
    "\n",
    "    g_min = m.addVar(lb=0.0, ub=1.0, name=\"g_min\")\n",
    "    g_max = m.addVar(lb=0.0, ub=1.0, name=\"g_max\")\n",
    "\n",
    "    Ctot = {}\n",
    "    C05 = {}\n",
    "    C512 = {}\n",
    "\n",
    "    for i in I:\n",
    "        expr_tot = gp.LinExpr()\n",
    "        expr_05 = gp.LinExpr()\n",
    "\n",
    "        for f in F:\n",
    "            if zip_f.get(f, \"\") == i:\n",
    "                expr_tot += nf.get(f, 0.0)\n",
    "                expr_tot += xF[f]\n",
    "                expr_05 += q05.get(f, 0.0)\n",
    "                expr_05 += z05[f]\n",
    "\n",
    "        for s in S:\n",
    "            if zip_s.get(s, \"\") == i:\n",
    "                for k in K:\n",
    "                    expr_tot += cap[k] * y_sk[s, k]\n",
    "                    expr_05 += u_sk05[s, k]\n",
    "\n",
    "        Ctot[i] = expr_tot\n",
    "        C05[i] = expr_05\n",
    "        C512[i] = expr_tot - expr_05\n",
    "\n",
    "\n",
    "    # (a) piecewise expansion definitions and ordering (as in Section 5)\n",
    "    for f in F:\n",
    "        n = float(nf.get(f, 0.0))\n",
    "        m.addConstr(x1[f] == 0.10 * n * y1[f], name=f\"x1_def_{f}\")\n",
    "        m.addConstr(x2[f] == 0.05 * n * y2[f], name=f\"x2_def_{f}\")\n",
    "        m.addConstr(x3[f] == 0.05 * n * y3[f], name=f\"x3_def_{f}\")\n",
    "        m.addConstr(y2[f] <= y1[f], name=f\"y2_le_y1_{f}\")\n",
    "        m.addConstr(y3[f] <= y2[f], name=f\"y3_le_y2_{f}\")\n",
    "        m.addConstr(xF[f] == x1[f] + x2[f] + x3[f], name=f\"xF_def_{f}\")\n",
    "        m.addConstr(xF[f] <= 0.20 * n, name=f\"xF_ub_{f}\")\n",
    "        m.addConstr(z05[f] <= xF[f], name=f\"z05_le_xF_{f}\")\n",
    "\n",
    "    # (b) site feasibility & 0-5 allocation\n",
    "    for s in S:\n",
    "        if allow.get(s, 1) == 0:\n",
    "            m.addConstr(gp.quicksum(y_sk[s, k] for k in K) == 0, name=f\"site_block_{s}\")\n",
    "        else:\n",
    "            m.addConstr(gp.quicksum(y_sk[s, k] for k in K) <= 1, name=f\"site_one_size_{s}\")\n",
    "        for k in K:\n",
    "            m.addConstr(u_sk05[s, k] <= cap05[k] * y_sk[s, k], name=f\"u_cap05_{s}_{k}\")\n",
    "\n",
    "    # (c) coverage-ratio identities (linear) and bounds\n",
    "    for i in I:\n",
    "    \n",
    "        Pi05_i = float(Pi05.get(i, 0.0))\n",
    "        Pi512_i = float(max(Pi.get(i, 0.0) - Pi05_i, 0.0))\n",
    "        Pi_tot_i = float(Pi.get(i, 0.0))\n",
    "\n",
    "        # P^{0–5} * r05 = C05\n",
    "        if Pi05_i > 0:\n",
    "            m.addConstr(r05[i] * Pi05_i == C05[i], name=f\"covid_identity_05_{i}\")\n",
    "        else:\n",
    "            m.addConstr(C05[i] == 0.0, name=f\"zero_pop_05_cap_{i}\")\n",
    "            m.addConstr(r05[i] == 0.0, name=f\"zero_pop_05_ratio_{i}\")\n",
    "\n",
    "        # P^{5–12} * r512 = C512\n",
    "        if Pi512_i > 0:\n",
    "            m.addConstr(r512[i] * Pi512_i == C512[i], name=f\"covid_identity_512_{i}\")\n",
    "        else:\n",
    "            m.addConstr(C512[i] == 0.0, name=f\"zero_pop_512_cap_{i}\")\n",
    "            m.addConstr(r512[i] == 0.0, name=f\"zero_pop_512_ratio_{i}\")\n",
    "\n",
    "        # Total: P * g_i = Ctot\n",
    "        if Pi_tot_i > 0:\n",
    "            m.addConstr(g[i] * Pi_tot_i == Ctot[i], name=f\"cov_identity_tot_{i}\")\n",
    "        else:\n",
    "            m.addConstr(Ctot[i] == 0.0, name=f\"zero_pop_tot_cap_{i}\")\n",
    "            m.addConstr(g[i] == 0.0, name=f\"zero_pop_tot_ratio_{i}\")\n",
    "\n",
    "\n",
    "    # (d) no-desert policy targets (Eq. 18)\n",
    "    for i in I:\n",
    "        Pi_tot_i = float(Pi.get(i, 0.0))\n",
    "        Pi05_i = float(Pi05.get(i, 0.0))\n",
    "        ti_val = float(ti.get(i, 1/3))\n",
    "\n",
    "        m.addConstr(Ctot[i] >= ti_val * Pi_tot_i, name=f\"no_desert_tot_{i}\")\n",
    "\n",
    "        m.addConstr(C05[i] >= (2.0 / 3.0) * Pi05_i, name=f\"no_desert_05_{i}\")\n",
    "\n",
    "    # (e) fairness gap constraints (Eq. 19–20)\n",
    "    for i in I:\n",
    "        m.addConstr(g_min <= g[i], name=f\"gmin_le_g_{i}\")\n",
    "        m.addConstr(g[i] <= g_max, name=f\"g_le_gmax_{i}\")\n",
    "\n",
    "    m.addConstr(g_max - g_min <= 0.1, name=\"max_gap_limit\")\n",
    "\n",
    "    # (f) global budget (Eq. 21)\n",
    "    budget_expr = gp.LinExpr()\n",
    "\n",
    "    for f in F:\n",
    "        budget_expr += c1.get(f, 0.0) * x1[f]\n",
    "        budget_expr += c2.get(f, 0.0) * x2[f]\n",
    "        budget_expr += c3.get(f, 0.0) * x3[f]\n",
    "\n",
    "    for s in S:\n",
    "        for k in K:\n",
    "            budget_expr += cost[k] * y_sk[s, k]\n",
    "\n",
    "    for f in F:\n",
    "        budget_expr += BETA * z05[f]\n",
    "    for s in S:\n",
    "        for k in K:\n",
    "            budget_expr += BETA * u_sk05[s, k]\n",
    "\n",
    "    m.addConstr(budget_expr <= B, name=\"global_budget\")\n",
    "\n",
    "    # (g) site-site conflict pairs (as in Section 5)\n",
    "    for (s1, s2) in pairs:\n",
    "        for k1 in K:\n",
    "            for k2 in K:\n",
    "                m.addConstr(y_sk[s1, k1] + y_sk[s2, k2] <= 1, name=f\"conf_{s1}_{s2}_{k1}_{k2}\")\n",
    "\n",
    "    # ---- Objective: maximize social coverage index (Eq. 15) ----\n",
    "    objective = gp.quicksum(W0_5 * r05[i] + W5_12 * r512[i] for i in I)\n",
    "    m.setObjective(objective, GRB.MAXIMIZE)\n",
    "\n",
    "    new_vars = {\n",
    "        \"r05\": r05, \"r512\": r512, \"g\": g,\n",
    "        \"g_min\": g_min, \"g_max\": g_max,\n",
    "        \"Ctot\": Ctot, \"C05\": C05, \"C512\": C512\n",
    "    }\n",
    "    return m, (xF, z05, y_sk, u_sk05, x1, x2, x3), new_vars\n",
    "\n",
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "def main():\n",
    "    areas, facs, sites, sizes = load_data()\n",
    "    sites = infer_sites(sites, facs)\n",
    "    pairs = conflict_pairs(sites)\n",
    "\n",
    "    print(\"[main] Building fairness model (Section 6)...\")\n",
    "    m, core_vars, new_vars = build_fairness_model(areas, facs, sites, sizes, pairs,\n",
    "                                                  time_limit=300, mip_gap=0.005, B=BUDGET_B)\n",
    "    print(\"[main] Optimizing fairness model...\")\n",
    "    m.optimize()\n",
    "\n",
    "    status = m.status\n",
    "    if status in (GRB.Status.OPTIMAL, GRB.Status.TIME_LIMIT, GRB.Status.SUBOPTIMAL):\n",
    "        print(f\"[main] Solver status {status}, Obj (social coverage) = {m.objVal:.6f}\")\n",
    "\n",
    "        print(f\"g_min = {new_vars['g_min'].X:.4f}, g_max = {new_vars['g_max'].X:.4f}\")\n",
    "        I = list(areas[\"zip_code_cleaned\"])\n",
    "        for i in I:\n",
    "            r05v = new_vars[\"r05\"][i].X if i in new_vars[\"r05\"] else float(\"nan\")\n",
    "            r512v = new_vars[\"r512\"][i].X if i in new_vars[\"r512\"] else float(\"nan\")\n",
    "            gv = new_vars[\"g\"][i].X if i in new_vars[\"g\"] else float(\"nan\")\n",
    "            Ctot_i = new_vars[\"Ctot\"][i].getValue()\n",
    "            C05_i = new_vars[\"C05\"][i].getValue()\n",
    "            print(f\"Area {i}: Ctot={Ctot_i:.1f}, C0-5={C05_i:.1f}, r0-5={r05v:.4f}, r5-12={r512v:.4f}, g={gv:.4f}\")\n",
    "\n",
    "        xF, z05, y_sk, u_sk05, x1, x2, x3 = core_vars\n",
    "        sel_sites = []\n",
    "        cap = dict(zip(sizes.k, sizes.cap_k))\n",
    "        zip_s = dict(zip(sites.site_id, sites.zip_code_cleaned))\n",
    "        for (s,k), var in y_sk.items():\n",
    "            if var.X > 0.5:\n",
    "                sel_sites.append((s, k, cap[k], zip_s.get(s, \"\")))\n",
    "        print(\"\\nSelected new sites:\")\n",
    "        if not sel_sites:\n",
    "            print(\"  (none)\")\n",
    "        else:\n",
    "            for s,k,capk,z in sel_sites:\n",
    "                print(f\"  site {s} ZIP {z} size {k} cap {capk}\")\n",
    "    else:\n",
    "        print(\"[main] Model not solved to optimality. Status:\", status, \"SolCount:\", m.SolCount)\n",
    "        if status in [GRB.Status.INFEASIBLE, GRB.Status.INF_OR_UNBD]:\n",
    "            print(\"[main] Model infeasible -> computing IIS...\")\n",
    "            m.computeIIS()\n",
    "            infeas = [c.constrName for c in m.getConstrs() if c.IISConstr]\n",
    "            print(\"[main] IIS constraints:\", infeas[:20])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0208e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
